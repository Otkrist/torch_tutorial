{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Tutorial\n",
    "\n",
    "An autoencoder is an unsupervised machine learning algorithm that takes an image as input and tries to reconstruct it using fewer number of bits from the bottleneck also known as latent space. The image is majorly compressed at the bottleneck. The compression in autoencoders is achieved by training the network for a period of time and as it learns it tries to best represent the input image at the bottleneck. An autoencoder neural network is an unsupervised learning algorithm that applies backpropagation, setting the target values to be equal to the inputs.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1574/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA Availability to [True]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import numpy\n",
    "\n",
    "_cuda_ = torch.cuda.is_available()\n",
    "\n",
    "print(\"Setting CUDA Availability to [%s]\" % str(_cuda_))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def imshow(npimg):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    #npimg = img.numpy()\n",
    "    #print npimg.shape\n",
    "    #plt.imshow(npimg.transpose(1,2,0))\n",
    "    #plt.show()\n",
    "    #plt.draw()\n",
    "    #plt.pause(0.001)\n",
    "    ax.clear()\n",
    "    ax.imshow(npimg.transpose(1,2,0))\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "def show_results():\n",
    "    tt = iter(DataLoader(dataset, batch_size=4, shuffle=False))\n",
    "    #tt.next()\n",
    "    imgin, _ = tt.next()\n",
    "    img = imgin.view(imgin.size(0), -1)\n",
    "    if _cuda_:\n",
    "        img = Variable(img).cuda()\n",
    "    else:\n",
    "        img = Variable(img)\n",
    "    # ===================forward=====================\n",
    "    output = model(img)\n",
    "    pic = to_img(output.cpu().data)\n",
    "    im1 = torchvision.utils.make_grid(imgin).numpy()\n",
    "    im2 = torchvision.utils.make_grid(pic).numpy()\n",
    "    imout = numpy.concatenate((im1, im2), 1)\n",
    "    imshow(imout)\n",
    "\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over here we will build a basic autoencoder. We will build an encoder and decoder and encoder will learn to represent the images in a compressed format.\n",
    "\n",
    "<img src=\"https://www.safaribooksonline.com/library/view/neural-network-programming/9781788390392/assets/9021ab47-abff-43f7-9771-b22eafa5d5ee.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True), nn.Linear(64, 12), nn.ReLU(True), nn.Linear(12, 3))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True), nn.Linear(128, 28 * 28), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if _cuda_:\n",
    "  model = autoencoder().cuda()\n",
    "else:\n",
    "  model = autoencoder()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #if epoch % 10 == 0:\n",
    "    for idx, data in enumerate(dataloader):\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if _cuda_:\n",
    "          img = Variable(img).cuda()\n",
    "        else:\n",
    "          img = Variable(img)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 20 == 0:\n",
    "            show_results()\n",
    "    # ===================log========================\n",
    "    #print('epoch [{}/{}], loss:{:.4f}'\n",
    "    #      .format(epoch + 1, num_epochs, loss.data[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
